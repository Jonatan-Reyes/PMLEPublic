{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from scipy.stats import bernoulli\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms, utils\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import exp\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OimlcBLxYkqc",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This UNET-style prediction model was originally included as part of the Score-based generative modelling tutorial \n",
    "# by Yang Song et al: https://colab.research.google.com/drive/120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3?usp=sharing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "  \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "  def __init__(self, embed_dim, scale=30.):\n",
    "    super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed \n",
    "    # during optimization and are not trainable.\n",
    "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "  def forward(self, x):\n",
    "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "  \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.dense = nn.Linear(input_dim, output_dim)\n",
    "  def forward(self, x):\n",
    "    return self.dense(x)[..., None, None]\n",
    "\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "  \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "  def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\n",
    "    \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "    Args:\n",
    "      marginal_prob_std: A function that takes time t and gives the standard\n",
    "        deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "      channels: The number of channels for feature maps of each resolution.\n",
    "      embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    # Gaussian random feature embedding layer for time\n",
    "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "         nn.Linear(embed_dim, embed_dim))\n",
    "    # Encoding layers where the resolution decreases\n",
    "    self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\n",
    "    self.dense1 = Dense(embed_dim, channels[0])\n",
    "    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "    self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\n",
    "    self.dense2 = Dense(embed_dim, channels[1])\n",
    "    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\n",
    "    self.dense3 = Dense(embed_dim, channels[2])\n",
    "    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\n",
    "    self.dense4 = Dense(embed_dim, channels[3])\n",
    "    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])    \n",
    "\n",
    "    # Decoding layers where the resolution increases\n",
    "    self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\n",
    "    self.dense5 = Dense(embed_dim, channels[2])\n",
    "    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)    \n",
    "    self.dense6 = Dense(embed_dim, channels[1])\n",
    "    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)    \n",
    "    self.dense7 = Dense(embed_dim, channels[0])\n",
    "    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "    self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], 1, 3, stride=1)\n",
    "    \n",
    "    # The swish activation function\n",
    "    self.act = lambda x: x * torch.sigmoid(x)\n",
    "    self.marginal_prob_std = marginal_prob_std\n",
    "  \n",
    "  def forward(self, x, t): \n",
    "    # Obtain the Gaussian random feature embedding for t   \n",
    "    embed = self.act(self.embed(t))    \n",
    "    # Encoding path\n",
    "    h1 = self.conv1(x)    \n",
    "    ## Incorporate information from t\n",
    "    h1 += self.dense1(embed)\n",
    "    ## Group normalization\n",
    "    h1 = self.gnorm1(h1)\n",
    "    h1 = self.act(h1)\n",
    "    h2 = self.conv2(h1)\n",
    "    h2 += self.dense2(embed)\n",
    "    h2 = self.gnorm2(h2)\n",
    "    h2 = self.act(h2)\n",
    "    h3 = self.conv3(h2)\n",
    "    h3 += self.dense3(embed)\n",
    "    h3 = self.gnorm3(h3)\n",
    "    h3 = self.act(h3)\n",
    "    h4 = self.conv4(h3)\n",
    "    h4 += self.dense4(embed)\n",
    "    h4 = self.gnorm4(h4)\n",
    "    h4 = self.act(h4)\n",
    "\n",
    "    # Decoding path\n",
    "    h = self.tconv4(h4)\n",
    "    ## Skip connection from the encoding path\n",
    "    h += self.dense5(embed)\n",
    "    h = self.tgnorm4(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv3(torch.cat([h, h3], dim=1))\n",
    "    h += self.dense6(embed)\n",
    "    h = self.tgnorm3(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv2(torch.cat([h, h2], dim=1))\n",
    "    h += self.dense7(embed)\n",
    "    h = self.tgnorm2(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "    # Normalize output\n",
    "    h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ExponentialMovingAverage implementation as used in pytorch visionUniversitet\n",
    "# https://github.com/pytorch/vision/blob/main/references/classification/utils.py#L159\n",
    "\n",
    "# BSD 3-Clause License\n",
    "\n",
    "# Copyright (c) Soumith Chintala 2016, \n",
    "# All rights reserved.\n",
    "\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "# * Redistributions of source code must retain the above copyright notice, this\n",
    "#   list of conditions and the following disclaimer.\n",
    "\n",
    "# * Redistributions in binary form must reproduce the above copyright notice,\n",
    "#   this list of conditions and the following disclaimer in the documentation\n",
    "#   and/or other materials provided with the distribution.\n",
    "\n",
    "# * Neither the name of the copyright holder nor the names of its\n",
    "#   contributors may be used to endorse or promote products derived from\n",
    "#   this software without specific prior written permission.\n",
    "\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "    \n",
    "class ExponentialMovingAverage(torch.optim.swa_utils.AveragedModel):\n",
    "    \"\"\"Maintains moving averages of model parameters using an exponential decay.\n",
    "    ``ema_avg = decay * avg_model_param + (1 - decay) * model_param``\n",
    "    `torch.optim.swa_utils.AveragedModel <https://pytorch.org/docs/stable/optim.html#custom-averaging-strategies>`_\n",
    "    is used to compute the EMA.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, decay, device=\"cpu\"):\n",
    "        def ema_avg(avg_model_param, model_param, num_averaged):\n",
    "            return decay * avg_model_param + (1 - decay) * model_param\n",
    "\n",
    "        super().__init__(model, device, ema_avg, use_buffers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "645d91e4bb974b1196be61b5077c9dc5",
      "78dc714c7aa347fb9fc41abf420222d9",
      "c1260f271df547fbb2a158ff6b3a3ff4",
      "e7313fdbb70442f4867644dfc85c3bcc",
      "a501588b5eb0494996dfb136565365ca",
      "89c68eded05d441daf94d145addb5ece",
      "2bffd3855f5744f588d5be1e5c4aed3e",
      "3b61ee9c62994863b718c086d4182f44",
      "8b905c5b2ad846ca837bd20cce2bf094",
      "b1416c32c4af4fe9a3c3fdcc5f33aca0",
      "aca161ff9f4b4a20b1457a8ee864f150"
     ]
    },
    "id": "mcoxR2ajYkqe",
    "outputId": "1f39bd8e-e78c-42e6-89cc-f1df34bdbdea"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, utils\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "\n",
    "    def __init__(self, network, T=100, beta_1=1e-4, beta_T=2e-2):\n",
    "        \"\"\"\n",
    "        Initialize Denoising Diffusion Probabilistic Model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        network: nn.Module\n",
    "            The inner neural network used by the diffusion process. Typically a Unet.\n",
    "        beta_1: float\n",
    "            beta_t value at t=1 \n",
    "        beta_T: [float]\n",
    "            beta_t value at t=T (last step)\n",
    "        T: int\n",
    "            The number of diffusion steps.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(DDPM, self).__init__()\n",
    "\n",
    "        # Normalize time input before evaluating neural network\n",
    "        # Reshape input into image format and normalize time value before sending it to network model\n",
    "        self._network = network\n",
    "        self.network = lambda x, t: (self._network(x.reshape(-1, 1, 28, 28), \n",
    "                                                   (t.squeeze()/T))\n",
    "                                    ).reshape(-1, 28*28)\n",
    "\n",
    "        # Total number of time steps\n",
    "        self.T = T\n",
    "\n",
    "        # Registering as buffers to ensure they get transferred to the GPU automatically\n",
    "        self.register_buffer(\"beta\", torch.linspace(beta_1, beta_T, T+1))\n",
    "        self.register_buffer(\"alpha\", 1-self.beta)\n",
    "        self.register_buffer(\"alpha_bar\", self.alpha.cumprod(dim=0))\n",
    "        \n",
    "\n",
    "    def forward_diffusion(self, x0, t, epsilon):\n",
    "        '''\n",
    "        q(x_t | x_0)\n",
    "        Forward diffusion from an input datapoint x0 to an xt at timestep t, provided a N(0,1) noise sample epsilon. \n",
    "        Note that we can do this operation in a single step\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0: torch.tensor\n",
    "            x value at t=0 (an input image)\n",
    "        t: int\n",
    "            step index \n",
    "        epsilon:\n",
    "            noise sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            image at timestep t\n",
    "        ''' \n",
    "\n",
    "        mean = torch.sqrt(self.alpha_bar[t])*x0\n",
    "        std = torch.sqrt(1 - self.alpha_bar[t])\n",
    "        \n",
    "        return mean + std*epsilon\n",
    "\n",
    "    def reverse_diffusion(self, xt, t, epsilon):\n",
    "        \"\"\"\n",
    "        p(x_{t-1} | x_t)\n",
    "        Single step in the reverse direction, from x_t (at timestep t) to x_{t-1}, provided a N(0,1) noise sample epsilon.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xt: torch.tensor\n",
    "            x value at step t\n",
    "        t: int\n",
    "            step index\n",
    "        epsilon:\n",
    "            noise sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            image at timestep t-1\n",
    "        \"\"\"\n",
    "\n",
    "        mean =  1./torch.sqrt(self.alpha[t]) * (xt - (self.beta[t])/torch.sqrt(1-self.alpha_bar[t])*self.network(xt, t)) \n",
    "        std = torch.where(t>0, torch.sqrt(((1-self.alpha_bar[t-1]) / (1-self.alpha_bar[t]))*self.beta[t]), 0)\n",
    "        \n",
    "        return mean + std*epsilon\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, shape):\n",
    "        \"\"\"\n",
    "        Sample from diffusion model (Algorithm 2 in Ho et al, 2020)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape: tuple\n",
    "            Specify shape of sampled output. For MNIST: (nsamples, 28*28)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            sampled image            \n",
    "        \"\"\"\n",
    "        \n",
    "        # Sample xT: Gaussian noise\n",
    "        xT = torch.randn(shape).to(self.beta.device)\n",
    "\n",
    "        xt = xT\n",
    "        for t in range(self.T, 0, -1):\n",
    "            noise = torch.randn_like(xT) if t > 1 else 0\n",
    "            t = torch.tensor(t).expand(xt.shape[0], 1).to(self.beta.device)            \n",
    "            xt = self.reverse_diffusion(xt, t, noise)\n",
    "\n",
    "        return xt\n",
    "\n",
    "    \n",
    "    def elbo_simple(self, x0):\n",
    "        \"\"\"\n",
    "        ELBO training objective (Algorithm 1 in Ho et al, 2020)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0: torch.tensor\n",
    "            Input image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            ELBO value            \n",
    "        \"\"\"\n",
    "\n",
    "        # Sample time step t\n",
    "        t = torch.randint(1, self.T, (x0.shape[0],1)).to(x0.device)\n",
    "        \n",
    "        # Sample noise\n",
    "        epsilon = torch.randn_like(x0)\n",
    "\n",
    "        # TODO: Forward diffusion to produce image at step t\n",
    "        xt = self.forward_diffusion(x0, t, epsilon)\n",
    "        \n",
    "        return -nn.MSELoss(reduction='mean')(epsilon, self.network(xt, t))\n",
    "\n",
    "    \n",
    "    def loss(self, x0):\n",
    "        \"\"\"\n",
    "        Loss function. Just the negative of the ELBO.\n",
    "        \"\"\"\n",
    "        return -self.elbo_simple(x0).mean()\n",
    "\n",
    "losses = []\n",
    "def train(model, optimizer, scheduler, dataloader, epochs, device, ema=True, per_epoch_callback=None):\n",
    "    \"\"\"\n",
    "    Training loop\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: nn.Module\n",
    "        Pytorch model\n",
    "    optimizer: optim.Optimizer\n",
    "        Pytorch optimizer to be used for training\n",
    "    scheduler: optim.LRScheduler\n",
    "        Pytorch learning rate scheduler\n",
    "    dataloader: utils.DataLoader\n",
    "        Pytorch dataloader\n",
    "    epochs: int\n",
    "        Number of epochs to train\n",
    "    device: torch.device\n",
    "        Pytorch device specification\n",
    "    ema: Boolean\n",
    "        Whether to activate Exponential Model Averaging\n",
    "    per_epoch_callback: function\n",
    "        Called at the end of every epoch\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup progress bar\n",
    "    total_steps = len(dataloader)*epochs\n",
    "    progress_bar = tqdm(range(total_steps), desc=\"Training\")\n",
    "\n",
    "    if ema:\n",
    "        ema_global_step_counter = 0\n",
    "        ema_steps = 10\n",
    "        ema_adjust = dataloader.batch_size * ema_steps / epochs\n",
    "        ema_decay = 1.0 - 0.995\n",
    "        ema_alpha = min(1.0, (1.0 - ema_decay) * ema_adjust)\n",
    "        ema_model = ExponentialMovingAverage(model, device=device, decay=1.0 - ema_alpha)                \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Switch to train mode\n",
    "        model.train()\n",
    "\n",
    "        global_step_counter = 0\n",
    "        for i, (x, _) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.loss(x)\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix(loss=f\"â €{loss.item():12.4f}\", epoch=f\"{epoch+1}/{epochs}\", lr=f\"{scheduler.get_last_lr()[0]:.2E}\")\n",
    "            progress_bar.update()\n",
    "\n",
    "            if ema:\n",
    "                ema_global_step_counter += 1\n",
    "                if ema_global_step_counter%ema_steps==0:\n",
    "                    ema_model.update_parameters(model)                \n",
    "        \n",
    "        if per_epoch_callback:\n",
    "            per_epoch_callback(ema_model.module if ema else model)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "T = 1000\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "# Rather than treating MNIST images as discrete objects, as done in Ho et al 2020, \n",
    "# we here treat them as continuous input data, by dequantizing the pixel values (adding noise to the input data)\n",
    "# Also note that we map the 0..255 pixel values to [-1, 1], and that we process the 28x28 pixel values as a flattened 784 tensor.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: x + torch.rand(x.shape)/255),    # Dequantize pixel values\n",
    "    transforms.Lambda(lambda x: (x-0.5)*2.0),                    # Map from [0,1] -> [-1, -1]\n",
    "    transforms.Lambda(lambda x: x.flatten())\n",
    "])\n",
    "\n",
    "# Download and transform train dataset\n",
    "dataloader_train = torch.utils.data.DataLoader(datasets.MNIST('./mnist_data', download=True, train=True, transform=transform),\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True)\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Construct Unet\n",
    "# The original ScoreNet expects a function with std for all the\n",
    "# different noise levels, such that the output can be rescaled.\n",
    "# Since we are predicting the noise (rather than the score), we\n",
    "\n",
    "\n",
    "# def reporter(model):\n",
    "#     \"\"\"Callback function used for plotting images during training\"\"\"\n",
    "    \n",
    "#     # Switch to eval mode\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         nsamples = 10\n",
    "#         samples = model.sample((nsamples,28*28)).cpu()\n",
    "        \n",
    "#         # Map pixel values back from [-1,1] to [0,1]\n",
    "#         samples = (samples+1)/2 \n",
    "#         samples = samples.clamp(0.0, 1.0)\n",
    "\n",
    "#         # Plot in grid\n",
    "#         grid = utils.make_grid(samples.reshape(-1, 1, 28, 28), nrow=nsamples)\n",
    "#         plt.gca().set_axis_off()\n",
    "#         plt.imshow(transforms.functional.to_pil_image(grid), cmap=\"gray\")\n",
    "#         plt.show()    \n",
    "\n",
    "# # Call training loop\n",
    "# train(model, optimizer, scheduler, dataloader_train, \n",
    "#       epochs=epochs, device=device, ema=True, per_epoch_callback=reporter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_139933/1969334411.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mnist_unet02.load_state_dict(torch.load('baseline_unet.pt'))\n",
      "/tmp/ipykernel_139933/1969334411.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model02.load_state_dict(torch.load('baseline.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist_unet01 = ScoreNet((lambda t: torch.ones(1).to(device)))\n",
    "# mnist_unet01.load_state_dict(torch.load('ddpmgunet01.pth'))\n",
    "# # Construct model\n",
    "# model01 = DDPM(mnist_unet01, T=T).to(device)\n",
    "# model01.load_state_dict(torch.load('ddpmg01.pth'))\n",
    "\n",
    "mnist_unet02 = ScoreNet((lambda t: torch.ones(1).to(device)))\n",
    "mnist_unet02.load_state_dict(torch.load('baseline_unet.pt'))\n",
    "# Construct model\n",
    "model02 = DDPM(mnist_unet02, T=T).to(device)\n",
    "model02.load_state_dict(torch.load('baseline.pt'))\n",
    "\n",
    "\n",
    "# mnist_unet05 = ScoreNet((lambda t: torch.ones(1).to(device)))\n",
    "# mnist_unet05.load_state_dict(torch.load('ddpmgunet05.pth'))\n",
    "# # Construct model\n",
    "# model05 = DDPM(mnist_unet05, T=T).to(device)\n",
    "# model05.load_state_dict(torch.load('ddpmg05.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plotrow(samples, nsamples):\n",
    "#     grid = utils.make_grid(samples.reshape(-1, 1, 28, 28), nrow=nsamples)\n",
    "#     plt.gca().set_axis_off()\n",
    "#     plt.imshow(transforms.functional.to_pil_image(grid), cmap=\"gray\")\n",
    "#     plt.show()   \n",
    "\n",
    "\n",
    "# def plotmodel (model, n, ctoken, weight):\n",
    "#     nsamples= n\n",
    "#     samples = model.sample((nsamples,28*28),ctoken,weight).cpu()\n",
    "#     samples = (samples+1)/2 \n",
    "#     samples = samples.clamp(0.0, 1.0)\n",
    "#     plotrow(samples = samples, nsamples= nsamples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotmodel(model01, 3, 4, 0)\n",
    "# plotmodel(model01, 3, 4, 3)\n",
    "# plotmodel(model01, 3, 4, 10)\n",
    "# plotmodel(model01, 3, 8, 0)\n",
    "# plotmodel(model01, 3, 8, 3)\n",
    "# plotmodel(model01, 3, 8, 10)\n",
    "# plotmodel(model01, 3, 11, 0)\n",
    "# plotmodel(model01, 3, 11, 3)\n",
    "# plotmodel(model01, 3, 11, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotmodel(model02, 3, 4, 0)\n",
    "# plotmodel(model02, 3, 4, 3)\n",
    "# plotmodel(model02, 3, 4, 10)\n",
    "# plotmodel(model02, 3, 8, 0)\n",
    "# plotmodel(model02, 3, 8, 3)\n",
    "# plotmodel(model02, 3, 8, 10)\n",
    "# plotmodel(model02, 3, 11, 0)\n",
    "# plotmodel(model02, 3, 11, 3)\n",
    "# plotmodel(model02, 3, 11, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotmodel(model05, 3, 4, 0)\n",
    "# plotmodel(model05, 3, 4, 3)\n",
    "# plotmodel(model05, 3, 4, 10)\n",
    "# plotmodel(model05, 3, 8, 0)\n",
    "# plotmodel(model05, 3, 8, 3)\n",
    "# plotmodel(model05, 3, 8, 10)\n",
    "# plotmodel(model05, 3, 11, 0)\n",
    "# plotmodel(model05, 3, 11, 3)\n",
    "# plotmodel(model05, 3, 11, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inceptionscore(p_yx, eps=1E-16):\n",
    "\tp_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "\tkl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "\tsum_kl_d = kl_d.sum(axis=1)\n",
    "\tavg_kl_d = mean(sum_kl_d)\n",
    "\tis_score = exp(avg_kl_d)\n",
    "\treturn is_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(numsamples, weight, classifier, sampler):\n",
    "    samples = sampler.sample((numsamples,28*28),8,weight).cpu()\n",
    "    samples = (samples+1)/2 \n",
    "    samples = samples.clamp(0.0, 1.0)\n",
    "    print(samples[0])\n",
    "    p_yx = classifier(samples[0].reshape(-1, 1, 224, 224))\n",
    "    is_score = inceptionscore(p_yx)\n",
    "    return is_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_139933/268409959.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  modelc.load_state_dict(torch.load( \"10epochresnet1.pt\"))\n"
     ]
    }
   ],
   "source": [
    "modelc = resnet50(weights=None)\n",
    "modelc.fc = nn.Linear(modelc.fc.in_features, 10)  \n",
    "modelc.load_state_dict(torch.load( \"10epochresnet1.pt\"))\n",
    "model = modelc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_139933/2539980505.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Images= torch.tensor(model02.sample((9984,28*28))).cpu()\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),             \n",
    "    transforms.Grayscale(3),                     \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x + torch.rand(x.shape)/255), \n",
    "    transforms.Lambda(lambda x: (x - 0.5) * 2.0)  \n",
    "])\n",
    "batch_size = 32\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./mnist_data', download=True, train=False, transform=transform),batch_size=batch_size,shuffle=True)\n",
    "\n",
    "Images= torch.tensor(model02.sample((9984,28*28))).cpu()\n",
    "target = torch.tensor([8]*9984)\n",
    "Images =(Images+1)/2 \n",
    "Images = Images.clamp(0.0, 1.0)\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, labels, images, transform=None):\n",
    "        self.labels = labels\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        target = self.labels[idx]\n",
    "        img = (img * 255).byte() \n",
    "        img = Image.fromarray(img.reshape(28,28).numpy(), mode=\"L\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "dataloader_t = torch.utils.data.DataLoader(CustomImageDataset(target, Images, transform=transform), batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "Marrginals = np.zeros(10)\n",
    "Labels = np.zeros(10)\n",
    "Margs2 = np.zeros(10)\n",
    "\n",
    "\n",
    "margs2 = []\n",
    "\n",
    "\n",
    "model.eval()\n",
    "aaaa = 0\n",
    "for image, label in dataloader_t:\n",
    "    image = image.to(device)\n",
    "    results = model(image)\n",
    "    softer = torch.softmax(results, dim=1).cpu().detach().numpy()\n",
    "    Marrginals += np.sum(softer,axis=0)\n",
    "    intermediate =np.zeros(10)\n",
    "    uncount = np.unique(np.argmax(softer,axis=1),return_counts=True)\n",
    "    #print(uncount)\n",
    "    for i, idx in enumerate(uncount[0]):\n",
    "        mew =uncount[1][i]\n",
    "        Labels[idx] += mew\n",
    "    margs2.append(softer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.073902"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array(margs2).reshape(-1,10)\n",
    "inceptionscore(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 854.16935918,  802.32152151, 1052.74381564, 1114.2568336 ,\n",
       "        827.87777582, 1101.04221528,  968.88073328,  899.91428832,\n",
       "       1270.10411663, 1092.68919464])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Marrginals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 859.,  811., 1055., 1108.,  825., 1099.,  983.,  912., 1245.,\n",
       "       1087.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 05, 9984, w11,c0 = inc7.867286 L[1090.,  443., 1147.,  941.,  781., 1037., 1078.,  819., 1413.,1235.], M[1074.87380897,  443.84543573, 1138.66734613,  945.91913356,784.76158282, 1022.75437452, 1087.24370515,  812.34048105,1440.32735717, 1233.26661023]\n",
    "## 02, 9984, w11,c0 = inc7.758951  L[ 783.  797. 1191.  839.  764. 1021.  974.  936. 1383. 1296.], M[ 774.96809188  803.21491529 1189.05144751  847.22906472  759.291075721019.23450698  977.26531453  926.97815027 1388.75051075 1298.01672992]\n",
    "## 01,  9984, w11,c0 = inc7.596831  L[ 984.  708. 1234. 1055.  625.  985.  864.  961. 1478. 1090.], M[ 978.61510494  693.77996466 1238.24022508 1077.49460599  628.53812312 969.68472415  876.43635325  939.58434962 1473.76162899 1107.86477476]\n",
    "\n",
    "#alle er 02 992\n",
    "# c4, w3 , IS 1.0158604, M[9.14554317e-04, 1.31661179e-03, 5.48751523e-02, 2.58897636e-04, 9.89762289e+02, 2.32008527e-02, 3.20213470e-03, 8.38938044e-01,6.06521536e-03, 1.30898097e+00, L [  0.,   0.,   0.,   0., 990.,   0.,   0.,   1.,   0.,   1.]\n",
    "# c4, w1 IS 2.064914, L[  3.,  22.,  14.,   5., 794.,   5.,  10.,  23.,  20.,  96.], IS, M[  3.65402198,  23.10517972,  14.55023521,   5.46638261, 786.2123909 ,   5.26430612,  11.5335885 ,  22.8150639 ,23.32563034,  96.07320043]\n",
    "# c4, w0.5 IS 5.183058, L[ 42.,  59.,  37.,  28., 379.,  52.,  50.,  62.,  95., 188.] ,  IS, M[ 39.31310181,  58.32266428,  37.73805947,  27.45305047, 379.5146389 ,  52.4145424 ,  49.98398673,  62.50474741, 95.53566608, 189.21953773]\n",
    "# c4, w0.1 IS 7.089525,L [ 68.,  60., 113.,  70.,  96., 111.,  84., 111., 137., 142.]),  IS, M[ 64.96757297,  62.94574855, 112.58474246,  75.31509727,95.71327247, 112.0472855 ,  85.22419912, 108.21339244,137.44275707, 137.54591238]\n",
    "\n",
    "\n",
    "# c1, w0.1 , IS, M\n",
    "# c1, w0.5 , IS, M\n",
    "# c1, w1 L ,  IS, M\n",
    "# c1, w3 L ,  IS, M\n",
    "\n",
    "# c9, w3 , IS1.0395116, M[1.31082626e+00, 7.57290578e-03, 1.64815339e-01, 5.06168577e-02, 5.47695134e-02, 1.43538031e+00, 1.06234250e-01, 1.41819337e+00,2.16399229e+00, 9.85287615e+02], L [  1.,   0.,   0.,   0.,   0.,   1.,   0.,   1.,   1., 988.]\n",
    "# c9, w1 , IS2.1260743, M[  9.11096856,   5.34596816,   9.45520284,  13.14214322,18.81080664,  25.45697429,   3.41885154,  55.7438764 ,64.86257201, 786.65265274] L [  8.,   5.,   9.,  13.,  18.,  27.,   3.,  58.,  58., 793.]\n",
    "# c9, w0.5 L ,  IS 4.812269, M[ 38.8679964 ,  29.38039424,  49.08564209,  49.63331288,57.02590223,  69.18777928,  19.47074284, 116.00421768,142.92653394, 420.41747284] L[ 40.,  29.,  47.,  48.,  58.,  70.,  19., 119., 141., 421.]\n",
    "# c9, w0.1 L ,  IS7.295546, [ 70.80666366,  76.05819075, 118.76730633,  78.19337916,72.6939941 ,  98.26101334,  61.58108045, 125.41675591,138.41015041, 151.81146431] L[ 74.,  79., 117.,  75.,  72.,  96.,  60., 129., 136., 154.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xxxx = [0,1,2,3,4,5,6,7,8,9]\n",
    "# fauxmargin = [1.31082626e+00, 7.57290578e-03, 1.64815339e-01, 5.06168577e-02, 5.47695134e-02, 1.43538031e+00, 1.06234250e-01, 1.41819337e+00,2.16399229e+00, 9.85287615e+02]\n",
    "# fauxlabel =  [  1.,   0.,   0.,   0.,   0.,   1.,   0.,   1.,   1., 988.]\n",
    "# fauxmargin = [  9.11096856,   5.34596816,   9.45520284,  13.14214322,18.81080664,  25.45697429,   3.41885154,  55.7438764 ,64.86257201, 786.65265274] \n",
    "# fauxlabel = [  8.,   5.,   9.,  13.,  18.,  27.,   3.,  58.,  58., 793.]\n",
    "barwidth = 0.3 \n",
    "br2 = [x + barwidth for x in xxxx] \n",
    "br3 = [x + barwidth for x in br2] \n",
    "\n",
    "plt.bar(xxxx,Labels/np.sum(Labels), alpha=1, width=barwidth, label='Label distrobutin')\n",
    "plt.bar(br2,Marrginals/np.sum(Marrginals), alpha=0.5,width=barwidth, label='Marginal ditrobution')\n",
    "plt.title(\"Boxplot of Marginal and Lable distrobution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks([r + barwidth/2 for r in range(len(Labels))], range(10))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2bffd3855f5744f588d5be1e5c4aed3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b61ee9c62994863b718c086d4182f44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "645d91e4bb974b1196be61b5077c9dc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78dc714c7aa347fb9fc41abf420222d9",
       "IPY_MODEL_c1260f271df547fbb2a158ff6b3a3ff4",
       "IPY_MODEL_e7313fdbb70442f4867644dfc85c3bcc"
      ],
      "layout": "IPY_MODEL_a501588b5eb0494996dfb136565365ca"
     }
    },
    "78dc714c7aa347fb9fc41abf420222d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89c68eded05d441daf94d145addb5ece",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2bffd3855f5744f588d5be1e5c4aed3e",
      "value": "Training:â€‡â€‡24%"
     }
    },
    "89c68eded05d441daf94d145addb5ece": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b905c5b2ad846ca837bd20cce2bf094": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a501588b5eb0494996dfb136565365ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aca161ff9f4b4a20b1457a8ee864f150": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1416c32c4af4fe9a3c3fdcc5f33aca0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1260f271df547fbb2a158ff6b3a3ff4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b61ee9c62994863b718c086d4182f44",
      "max": 5900,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b905c5b2ad846ca837bd20cce2bf094",
      "value": 1394
     }
    },
    "e7313fdbb70442f4867644dfc85c3bcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1416c32c4af4fe9a3c3fdcc5f33aca0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_aca161ff9f4b4a20b1457a8ee864f150",
      "value": "â€‡1393/5900â€‡[05:15&lt;16:04,â€‡â€‡4.67it/s,â€‡epoch=12/50,â€‡loss=â €â€‡â€‡â€‡2400.1270]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
